# -*- coding: utf-8 -*-
"""crawling+sentiment+cleaning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I5mL-OjjWWX0_hyUsSrG5BLFd93xYR-K
"""

import pandas as pd
from googleapiclient.discovery import build

def video_comments(video_id):
	# empty list for storing reply
	replies = []

	# creating youtube resource object
	youtube = build('youtube', 'v3', developerKey=api_key)

	# retrieve youtube video results
	video_response = youtube.commentThreads().list(part='snippet,replies', videoId=video_id).execute()

	# iterate video response
	while video_response:

		# extracting required info
		# from each result object
		for item in video_response['items']:

			# Extracting comments ()
			published = item['snippet']['topLevelComment']['snippet']['publishedAt']
			user = item['snippet']['topLevelComment']['snippet']['authorDisplayName']

			# Extracting comments
			comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
			likeCount = item['snippet']['topLevelComment']['snippet']['likeCount']

			replies.append([published, user, comment, likeCount])

			# counting number of reply of comment
			replycount = item['snippet']['totalReplyCount']

			# if reply is there
			if replycount>0:
				# iterate through all reply
				for reply in item['replies']['comments']:

					# Extract reply
					published = reply['snippet']['publishedAt']
					user = reply['snippet']['authorDisplayName']
					repl = reply['snippet']['textDisplay']
					likeCount = reply['snippet']['likeCount']

					# Store reply is list
					#replies.append(reply)
					replies.append([published, user, repl, likeCount])

			# print comment with list of reply
			#print(comment, replies, end = '\n\n')

			# empty reply list
			#replies = []

		# Again repeat
		if 'nextPageToken' in video_response:
			video_response = youtube.commentThreads().list(
					part = 'snippet,replies',
					pageToken = video_response['nextPageToken'],
					videoId = video_id
				).execute()
		else:
			break
	#endwhile
	return replies

# isi api key
api_key = 'AIzaSyAKtyxyn4-IFtcHK_wRc2pTu0SieVVVmSE'

# Enter video id
# url video = https://www.youtube.com/watch?v=5cYwoBYCvec&ab_channel=MaryAngline
video_id = "5cYwoBYCvec" #isi kode / ID video

# Call function
comments = video_comments(video_id)

comments

df = pd.DataFrame(comments, columns=['publishedAt', 'authorDisplayName', 'textDisplay', 'likeCount'])
df

df.to_csv('youtube-comments.csv', index=False)

df.to_excel('youtube-comments.xlsx', index=False)

from textblob import TextBlob

def analyze_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return 'Positif'
    elif analysis.sentiment.polarity == 0:
        return 'Netral'
    else:
        return 'Negatif'

df['sentiment'] = df['textDisplay'].apply(analyze_sentiment)

selected_columns = df[['publishedAt', 'authorDisplayName', 'textDisplay', 'likeCount', 'sentiment']]

print(selected_columns)

selected_columns.to_csv('selected_data.csv', index=False)

selected_columns.to_excel('selected_data.xlsx', index=False)